{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a875c01-bb42-4bbc-a118-5c0c9ba2ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:01:46.265032: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 20:01:46.641215: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-30 20:01:47.607558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2022-11-30 20:01:47.607619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64\n",
      "2022-11-30 20:01:47.607623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import lil_matrix,csr_matrix, save_npz, load_npz\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dropout, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7acaa1f-5eb2-4476-9a69-e114d5e13fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the folders for the project\n",
    "output_path = 'output'\n",
    "input_path = 'input'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "if not os.path.exists(input_path):\n",
    "    os.makedirs(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ee1b6a-1d7d-4182-8cb9-faef338d770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-30 20:01:48--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 198702078 (189M) [application/zip]\n",
      "Saving to: ‘ml-20m.zip’\n",
      "\n",
      "ml-20m.zip          100%[===================>] 189,50M  19,7MB/s    in 19s     \n",
      "\n",
      "2022-11-30 20:02:07 (10,2 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
      "\n",
      "Archive:  ml-20m.zip\n",
      "   creating: ml-20m/\n",
      "  inflating: ml-20m/genome-scores.csv  \n",
      "  inflating: ml-20m/genome-tags.csv  \n",
      "  inflating: ml-20m/links.csv        \n",
      "  inflating: ml-20m/movies.csv       \n",
      "  inflating: ml-20m/ratings.csv      \n",
      "  inflating: ml-20m/README.txt       \n",
      "  inflating: ml-20m/tags.csv         \n"
     ]
    }
   ],
   "source": [
    "# Download the dataset if not existing\n",
    "!wget -nc http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
    "!unzip -n ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f897f51-618b-4249-b934-2fd603999c17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing step\n",
    "try:\n",
    "    # Try reading the preprocessed file if existing, if not generate\n",
    "    ratings_df = pd.read_csv(os.path.join(input_path, 'ratings_preprocessed.csv'))\n",
    "except:\n",
    "    # Read the original file\n",
    "    ratings_df = pd.read_csv(os.path.join('ml-20m', 'ratings.csv'))\n",
    "    # Make the userId start from zero\n",
    "    ratings_df['userId'] = ratings_df['userId'] - 1\n",
    "\n",
    "    # Create a mapping for movieId since they are not sequential\n",
    "    unique_movie_ids = set(ratings_df['movieId'].values)\n",
    "    movie2idx = {}\n",
    "    for i, movie_id in enumerate(unique_movie_ids):\n",
    "        movie2idx[movie_id] = i\n",
    "    # Add them to ratings_df\n",
    "    ratings_df['movie_idx'] = ratings_df.apply(lambda row: movie2idx[row['movieId']], axis=1)\n",
    "\n",
    "    # No need the timestamp of the rating\n",
    "    ratings_df.drop(columns=['timestamp'], inplace=True)\n",
    "\n",
    "    # Save the new ratings_df\n",
    "    ratings_df.to_csv(os.path.join(input_path, 'ratings_preprocessed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b998738b-342c-459a-824e-333a4d9bc489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138493, 131263)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = ratings_df['userId'].max() + 1\n",
    "M = ratings_df['movieId'].max() + 1\n",
    "\n",
    "N, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df930687-af8b-4edc-aa62-f517c5fa9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse_matrix(N, M, df):\n",
    "    A = lil_matrix((N, M))\n",
    "    \n",
    "    def update_sparse_matrix(row):\n",
    "        i = int(row['userId'])\n",
    "        j = int(row['movieId'])\n",
    "        \n",
    "        A[i, j] = row['rating']\n",
    "        \n",
    "    df.apply(update_sparse_matrix, axis=1)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c5e10d-400a-48d0-a347-f4f63b271edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sparse matrix for train and test\n",
    "# lil better for adding new values, csr better for saving\n",
    "df = shuffle(ratings_df)\n",
    "\n",
    "cut_off = int(0.8 * len(df.index))\n",
    "df_train = df.iloc[:cut_off]\n",
    "df_test = df.iloc[cut_off:]\n",
    "\n",
    "A_train = make_sparse_matrix(N, M, df_train)\n",
    "A_train = A_train.tocsr()\n",
    "mask_train = (A_train > 0)\n",
    "save_npz(os.path.join(input_path, 'A_train.npz'), A_train)\n",
    "\n",
    "A_test = make_sparse_matrix(N, M, df_test)\n",
    "A_test = A_test.tocsr()\n",
    "mask_test = (A_test > 0)\n",
    "save_npz(os.path.join(input_path, 'A_test.npz'), A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1453f799-fad3-4bc3-9832-cb5fd729c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "regularization = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be33388-fbe8-457b-a4a1-519399c88512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.525553664608152\n"
     ]
    }
   ],
   "source": [
    "mu = A_train.sum() / mask_train.sum()\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e64db8-0476-47c0-abc0-047a3fe45525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    mask = K.cast(K.not_equal(y_true, 0), dtype='float32')\n",
    "    diff = y_pred - y_true\n",
    "    sqdiff = diff * diff * mask\n",
    "    sse = K.sum(K.sum(sqdiff))\n",
    "    n = K.sum(K.sum(mask))\n",
    "    \n",
    "    return sse / n\n",
    "\n",
    "def generator(A, M):\n",
    "    while True:\n",
    "        A, M = shuffle(A, M)\n",
    "        for i in range(A.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1) * batch_size, A.shape[0])\n",
    "            a = A[i*batch_size: upper].toarray()\n",
    "            m = M[i*batch_size: upper].toarray()\n",
    "            a = a - mu * m\n",
    "\n",
    "            yield a, a\n",
    "\n",
    "def generator_test(A, M, A_test, M_test):\n",
    "    while True:\n",
    "        A, M = shuffle(A, M)\n",
    "        for i in range(A.shape[0] // batch_size + 1):\n",
    "            upper = min((i+1) * batch_size, A.shape[0])\n",
    "            a = A[i*batch_size: upper].toarray()\n",
    "            m = M[i*batch_size: upper].toarray()\n",
    "            at = A_test[i*batch_size: upper].toarray()\n",
    "            mt = M_test[i*batch_size: upper].toarray()\n",
    "            a = a - mu * m\n",
    "            at = at - mu * mt\n",
    "\n",
    "            yield a, at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a995739-a279-43ea-abf3-2261daff841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:05:40.861903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:40.946867: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:40.948865: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:40.952330: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 20:05:40.954430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:40.955940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:40.957360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:41.820361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:41.821383: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:41.821774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-30 20:05:41.822147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7715 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "i = Input(shape=(M,))\n",
    "x = Dropout(0.7)(i)\n",
    "x = Dense(700, activation='tanh', kernel_regularizer=l2(regularization))(x)\n",
    "x = Dense(M, kernel_regularizer=l2(regularization))(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "model.compile(\n",
    "    loss=mse_loss,\n",
    "    optimizer='adam',\n",
    "    metrics=[mse_loss],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0717c19-99ee-4a93-82ac-7bb705292856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:05:44.172142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-11-30 20:05:44.301844: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fd29c027300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-11-30 20:05:44.301856: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2022-11-30 20:05:44.327210: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1082 [..............................] - ETA: 43:57 - loss: 1.4986 - mse_loss: 1.2201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:05:44.636681: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082/1082 [==============================] - ETA: 0s - loss: 0.8398 - mse_loss: 0.6859"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    generator(A_train.copy(), mask_train.copy()),\n",
    "    validation_data=generator_test(A_train.copy(), mask_train.copy(), A_test.copy(), mask_test.copy()),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=A_train.shape[0] // batch_size + 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8019f1-8393-4a52-93df-3fead1e0b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c60bb41-83ca-433c-ab88-56e01326a946",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['mse_loss'], label='train mse')\n",
    "plt.plot(history.history['val_mse_loss'], label='test mse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44115653-1593-4301-a82c-41991210a2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
